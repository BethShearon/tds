{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Networks for EMNIST \n",
    "\n",
    "#### YouTube Link:\n",
    "https://youtu.be/HeoC8clFKN4\n",
    "\n",
    "#### Description:\n",
    "These next few weeks we will walk through the complete development of a Neural Network Project, focused on the Extended MNIST (EMNIST) dataset (https://www.nist.gov/itl/iad/image-group/emnist-dataset), as explored in Yann Lecun's site: http://yann.lecun.com/exdb/mnist/. \n",
    "\n",
    "Overview:\n",
    "- Load Data\n",
    "- Prepare Data\n",
    "- Define and Compile Model\n",
    "- Train Model\n",
    "- Inspect Model performance with Tensorboard\n",
    "\n",
    "Coming Soon:\n",
    "- Model construction\n",
    "    - Dense Layers\n",
    "    - Convolutional Layers\n",
    "\n",
    "#### References: \n",
    "- **Callbacks**: \n",
    "    - Machine Learning Mastery: https://machinelearningmastery.com/check-point-deep-learning-models-keras/\n",
    "    - Keras Documentation: https://keras.io/callbacks/\n",
    "- (Last semester reference): http://localhost:8889/notebooks/03.19%20Introduction%20to%20Keras%20Pt%202%20-%20Mijael/Keras_mnist_cnn.ipynb)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### _Initialize_ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "\n",
    "import gzip\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import struct\n",
    "import os\n",
    "import random\n",
    "\n",
    "#JustKerasThings~\n",
    "import keras\n",
    "from keras.models import load_model\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "# from keras.callbacks import ModelCheckpoint\n",
    "from keras.callbacks import TensorBoard\n",
    "from keras import backend\n",
    "\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Project Path: NOTE: Change to your username before use!\n",
    "project_path = '/Users/shegocaga/TDS/TDS-python-nn-18-fall/lecture_materials/2018-10-15 The EMNIST Dataset/'\n",
    "\n",
    "# Folder containing EMNIST download:\n",
    "download_path = project_path + 'gzip/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_idx(filename):\n",
    "    # the idx file format can be found at the bottom of http://yann.lecun.com/exdb/mnist/\n",
    "    print('Processing data from %s.' % filename)\n",
    "    with gzip.open(filename, 'rb') as f:\n",
    "        # read the \"magic number\" first\n",
    "        z, dtype, dim = struct.unpack('>HBB', f.read(4))\n",
    "        print(\"Dimensions:\", dim)\n",
    "        # get the shape (size in each dimension) of the data\n",
    "        shape = tuple(struct.unpack('>I', f.read(4))[0] for d in range(dim))\n",
    "        print(\"Shape:\", shape)\n",
    "        # return the data as a reshaped numpy array\n",
    "        return np.frombuffer(f.read(), dtype=np.uint8).reshape(shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_emnist():\n",
    "    # the dataset can be found here: http://www.itl.nist.gov/iaui/vip/cs_links/EMNIST/gzip.zip\n",
    "    train_images = download_path + 'emnist-byclass-train-images-idx3-ubyte.gz'\n",
    "    train_labels = download_path + 'emnist-byclass-train-labels-idx1-ubyte.gz'\n",
    "    test_images = download_path + 'emnist-byclass-test-images-idx3-ubyte.gz'\n",
    "    test_labels = download_path + 'emnist-byclass-test-labels-idx1-ubyte.gz'\n",
    "\n",
    "    train_X = read_idx(train_images)\n",
    "    train_y = read_idx(train_labels)\n",
    "    test_X = read_idx(test_images)\n",
    "    test_y = read_idx(test_labels)\n",
    "\n",
    "    return (train_X, train_y, test_X, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_train_X, raw_train_y, raw_test_X, raw_test_y = load_emnist();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(raw_train_X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "plt.imshow(raw_train_X[55].T, cmap='gray')\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib tk\n",
    "\n",
    "# Label (category) Mapping:\n",
    "labels = '0123456789ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz'\n",
    "\n",
    "Scrolling visualizer\n",
    "fig, ax = plt.subplots()\n",
    "for x in range(raw_train_X.shape[0]):\n",
    "    ax.clear()\n",
    "    ax.imshow([i for i in 255 - raw_train_X[x].T], cmap='gray')\n",
    "    title = 'label = %d = %s' % (raw_train_y[x], labels[raw_train_y[x]])\n",
    "    ax.set_title(title, fontsize=20)\n",
    "    plt.pause(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Data + Labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Shape!\n",
    "_Inputs for models must be 1-D arrays!_ (luckily Keras takes care of this for us)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#keras.backend.image_data_format()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shape of the datasets\n",
    "print('train_X shape: ', raw_train_X.shape)\n",
    "print('train_y shape: ', raw_train_y.shape)\n",
    "print('test_X shape: ', raw_test_X.shape)\n",
    "print('test_y shape: ', raw_test_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the dimensions of the input images\n",
    "img_height = len(raw_train_X[0])\n",
    "img_width = len(raw_train_X[1])\n",
    "input_shape = img_height*img_width\n",
    "\n",
    "print('Original Image Dimensions: ', img_height, img_width)\n",
    "print('Flattened image length: ', input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X = raw_train_X.reshape(len(raw_train_X), input_shape)\n",
    "test_X = raw_test_X.reshape(len(raw_test_X), input_shape)\n",
    "\n",
    "print('Training dataset shape: ', train_X.shape)\n",
    "print('Model input shape: ', input_shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Values start as integers:\n",
    "print(train_X.dtype)\n",
    "\n",
    "# Set as float32's\n",
    "train_X = train_X.astype('float32')\n",
    "test_X = test_X.astype('float32')\n",
    "\n",
    "# Normalize! \n",
    "train_X /= 255\n",
    "test_X /= 255\n",
    "\n",
    "print('Flattened length of numpy data array: ',img_height*img_width)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Labels: One-hot encode\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label (category) Mapping:\n",
    "labels = '0123456789ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz'\n",
    "label_vec = labels.split()\n",
    "\n",
    "# Save number of categories\n",
    "n_cat = len(labels)\n",
    "\n",
    "print('Number of categories: ', n_cat)\n",
    "print(labels[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y = keras.utils.np_utils.to_categorical(raw_train_y)\n",
    "test_y = keras.utils.np_utils.to_categorical(raw_test_y)\n",
    "print('One-hot encoded label dimensions: ', test_y.shape)\n",
    "test_y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Building\n",
    "Note that keras.layers.dense requires a flattened array as an input. This model does this automatically, provided the proper dimensions. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential()\n",
    "model.add(Dense(16, input_dim=input_shape, activation='relu'))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(20, activation='relu'))\n",
    "model.add(Dense(n_cat, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compile the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save state of training using callbacks:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checkpoint\n",
    "log_path = project_path + 'logs/'\n",
    "# tensorboard = Tensorboard(filepath, monitor='val_acc', verbose=1, save_best_only=False, mode='max')\n",
    "tensorboard = TensorBoard(log_dir=log_path, histogram_freq=0, write_graph=True)\n",
    "callbacks_list = [tensorboard]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(train_X, train_y, epochs=2, batch_size=2000, callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this before monday workshop, hoping this runs in time!\n",
    "for epoch_iter in [1,10,20,50]:\n",
    "    for batch_iter in [100,500,1000,5000,10000]:\n",
    "        model.fit(train_X, train_y, epochs=epoch_iter, batch_size=batch_iter, callbacks=callbacks_list)\n",
    "        print('Epoch range '+str(epoch_iter)+' and batch size '+str(batch_iter)+' complete!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = model.evaluate(test_X, test_y)\n",
    "print(\"\\nLoss: %.2f%%, Accuracy: %.2f%%\" % (results[0]*100, results[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Make a few predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(raw_test_X.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "# Select a 'random' subset\n",
    "random.seed(112358)\n",
    "sample = np.arange(raw_test_X.shape[0])\n",
    "np.random.shuffle(sample)\n",
    "sample = sample[0:10]\n",
    "\n",
    "# Format for input into network\n",
    "results = np.round(model.predict(test_X[sample], verbose=1), decimals=2)\n",
    "resultLabels = np.argmax(results, axis=1)\n",
    "\n",
    "# plt.imshow(raw_train_X[55].T, cmap='gray')\n",
    "\n",
    "fig=plt.figure(figsize=(15, 8))\n",
    "for i in range(10):\n",
    "    fig.add_subplot(2, 5, i+1, aspect='equal')\n",
    "    plt.imshow(raw_test_X[sample[i]].T, cmap='gray')\n",
    "    plt.title('Class {}'.format(labels[resultLabels[i]]))\n",
    "    plt.xlabel(\"Img {}\".format(sample[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(resultLabels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
